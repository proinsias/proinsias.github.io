---
layout: single
title: 'Why Should I Trust You?: Explaining the Predictions of Any Classifier'
excerpt: People don't trust black-box models
date: 2017-01-09
last_modified_at: 2022-11-10
categories: posts
tags:
    - explainability
    - interpretability
---

If you can't understand how a model makes a prediction, how can you trust that prediction?

> LIME [is] a novel explanation technique that explains the predictions of any classifier
> in an interpretable and faithful manner, by learning an interpretable model locally around the prediction.

(via [Why Should I Trust You?: Explaining the Predictions of Any Classifier](https://arxiv.org/abs/1602.04938))
