---
layout: single
title: "Why You're Not Getting Value from Your Data Science"
excerpt: >-
    If companies want to get value from their data, they need to focus on accelerating human understanding of data,
    scaling the number of modeling questions they can ask of that data in a short amount of time, and assessing their implications.
date: 2023-05-16 17:48
last_modified_at: 2023-05-17 02:39:00
categories:
    - tips
tags:
    - data-science
    - impact
    - machine-learning
---

As a Data Science manager at [LeanTaaS](https://leantaas.com), I strive to maximize the return on investment (or ROI) of expensive time from Data Scientists into new products.

In the [Harvard Business Review](https://hbr.org/2016/12/why-youre-not-getting-value-from-your-data-science), [Kalyan Veeramachaneni](http://www.kalyanv.org/) has a great discussion of principles to meet this goal:

> If companies want to get value from their data, they need to focus on accelerating human understanding of data, scaling the number of modeling questions they can ask of that data in a short amount of time, and assessing their implications. In our work with companies, we ultimately decided that creating true impact via machine learning will come from a focus on four principles:
>
> -   **Stick with simple models:** We decided that simple models, like logistic regression or those based on [random forests](https://en.wikipedia.org/wiki/Random_forest) or decision trees, are sufficient for the problems at hand. The focus should instead be on reducing the time between the data acquisition and the development of the first simple predictive model.
> -   **Explore more problems:** Data scientists need the ability to rapidly define and explore multiple prediction problems, quickly and easily. Instead of exploring one business problem with an incredibly sophisticated machine learning model, companies should be exploring dozens, building a simple predictive model for each one and assessing their value proposition.
> -   **Learn from a sample of data—not all the data:** Instead of focusing on how to apply distributed computing to allow any individual processing module to handle big data, invest in techniques that will enable the derivations of similar conclusions from a data subsample. By circumventing the use of massive computing resources, they will enable the exploration of more hypotheses.
> -   **Focus on automation:** To achieve both _reduced time to first model_ and _increased rate of exploration_, companies must automate processes that are normally done manually. Over and over across different data problems, we found ourselves applying similar data processing techniques, whether it was to transform the data into useful aggregates, or to prepare data for predictive modeling—it's time to streamline these, and to develop algorithms and build software systems that do them automatically.
