---
layout: single
title: "Why Should I Trust You?: Explaining the Predictions of Any Classifier"
date: 2017-01-09 13:01
modified: 2017-01-09 13:01
tags:
  - explainability
  - interpretability
---

If you can't understand how a model makes a prediction, how can you trust that prediction?

> LIME [is] a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction.

(via [Why Should I Trust You?: Explaining the Predictions of Any Classifier](https://arxiv.org/abs/1602.04938))

